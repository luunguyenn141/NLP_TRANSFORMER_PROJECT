import os
import sys
import torch

# Ensure `src/` is on sys.path so imports like `from model.transformer import Transformer` work
# when running the test from project root or other working directories.
src_dir = os.path.dirname(os.path.abspath(__file__))
if src_dir not in sys.path:
    sys.path.insert(0, src_dir)

from model.transformer import Transformer

def test_transformer_architecture():
    print("=== B·∫ÆT ƒê·∫¶U KI·ªÇM TRA M√î H√åNH TRANSFORMER ===")
    
    # 1. Gi·∫£ l·∫≠p si√™u tham s·ªë (Hyperparameters)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: {device}")

    src_vocab_size = 1000  # Gi·∫£ s·ª≠ vocab ngu·ªìn c√≥ 1000 t·ª´
    trg_vocab_size = 1000  # Gi·∫£ s·ª≠ vocab ƒë√≠ch c√≥ 1000 t·ª´
    src_pad_idx = 0        # Index c·ªßa token padding
    trg_pad_idx = 0
    
    # C√°c tham s·ªë ki·∫øn tr√∫c
    d_model = 512
    n_layers = 3     # Test th·ª≠ 3 l·ªõp cho nh·∫π
    n_heads = 8
    d_ff = 2048
    dropout = 0.1
    max_len = 100

    # 2. Kh·ªüi t·∫°o m√¥ h√¨nh
    try:
        model = Transformer(
            src_vocab_size, trg_vocab_size, 
            src_pad_idx, trg_pad_idx,
            d_model, n_layers, n_heads, 
            d_ff, dropout, max_len
        ).to(device)
        print("‚úÖ Kh·ªüi t·∫°o m√¥ h√¨nh th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o m√¥ h√¨nh: {e}")
        return

    # 3. T·∫°o d·ªØ li·ªáu gi·∫£ (Dummy Data)
    batch_size = 2
    src_len = 10
    trg_len = 12 # L∆∞u √Ω: trg_len th∆∞·ªùng kh√°c src_len

    # T·∫°o tensor ng·∫´u nhi√™n (gi·∫£ l·∫≠p index c·ªßa c√°c t·ª´)
    # Range t·ª´ 1 ƒë·∫øn vocab_size (tr√°nh s·ªë 0 v√¨ l√† padding)
    src = torch.randint(1, src_vocab_size, (batch_size, src_len)).to(device)
    trg = torch.randint(1, trg_vocab_size, (batch_size, trg_len)).to(device)

    # Th·ª≠ g√°n v√†i v·ªã tr√≠ l√† padding ƒë·ªÉ xem mask c√≥ l·ªói kh√¥ng
    src[0, -2:] = 0  # C√¢u 1 trong batch b·ªã pad 2 t·ª´ cu·ªëi
    trg[0, -1:] = 0  # C√¢u 1 trong batch ƒë√≠ch b·ªã pad 1 t·ª´ cu·ªëi

    print(f"\nInput shape (Source): {src.shape}")
    print(f"Input shape (Target): {trg.shape}")

    # 4. Ch·∫°y Forward Pass
    try:
        output = model(src, trg)
        print("‚úÖ Forward pass ch·∫°y th√†nh c√¥ng!")
    except RuntimeError as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh Forward: {e}")
        print("G·ª£i √Ω: Ki·ªÉm tra k·ªπ dimension trong file encoder.py ho·∫∑c decoder.py")
        return

    # 5. Ki·ªÉm tra Output Shape
    # Output mong ƒë·ª£i: [batch_size, trg_len, trg_vocab_size]
    expected_shape = torch.Size([batch_size, trg_len, trg_vocab_size])
    
    print(f"\nOutput shape th·ª±c t·∫ø: {output.shape}")
    print(f"Output shape mong ƒë·ª£i: {expected_shape}")

    if output.shape == expected_shape:
        print("\nüéâ CH√öC M·ª™NG! M√î H√åNH C·ª¶A B·∫†N ƒê√É CH·∫†Y CHU·∫®N V·ªÄ M·∫∂T KI·∫æN TR√öC.")
        print("S·∫µn s√†ng ƒë·ªÉ chuy·ªÉn sang b∆∞·ªõc Train.")
    else:
        print("\n‚ö†Ô∏è C·∫¢NH B√ÅO: K√≠ch th∆∞·ªõc ƒë·∫ßu ra kh√¥ng ƒë√∫ng!")

if __name__ == "__main__":
    test_transformer_architecture()